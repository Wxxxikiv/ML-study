{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = t.randn(1,1,32,32)\n",
    "output = net(input)\n",
    "target = t.arange(0,10).view(1,10).float()\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "print(net.conv1.bias.grad)\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "show = transforms.ToPILImage()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "    root='./data/cifar10/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "trainloader = t.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = tv.datasets.CIFAR10(\n",
    "    root='./data/cifar10/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testloader = t.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(classes[label])\n",
    "show((data+1)/2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改上面的LeNet网络处理CIFAR10数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "# GPU\n",
    "#device = t.device('cuda:0' if t.cuda.is_available() else 'cpu')\n",
    "#net.to(device=device)\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        (input, labels) = data\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch+1}, {i+1}], loss: {running_loss/2000}')\n",
    "            running_loss = 0.0\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(testloader)\n",
    "image, labels = testiter.__next__()\n",
    "print(\"labels : \", \"    \".join([classes[labels[i]] for i in range(4)]))\n",
    "show(tv.utils.make_grid((image+1)/2)).resize((400,100))\n",
    "output = net(image)\n",
    "_, predicted = t.max(output.data, 1)\n",
    "print(\"predicted : \", \"    \".join([classes[predicted[i]] for i in range(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with t.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        _, predicted = t.max(output.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print(total, correct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = t.randn(3, 128, 256)\n",
    "img = img.view(3, -1)\n",
    "img.mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet32 深度残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcat=None):\n",
    "        super().__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.right = shortcat\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        output += residual\n",
    "        return F.relu(output)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(64, 64, 3,1,is_shortcat=False)\n",
    "        self.layer2 = self._make_layer(64, 128,4,2)\n",
    "        self.layer3 = self._make_layer(128, 256,6,2)\n",
    "        self.layer4 = self._make_layer(256, 512,3,2)\n",
    "        self.classifies = nn.Linear(512, num_classes)\n",
    "    \n",
    "    \n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride, is_shortcat=True):\n",
    "        if is_shortcat:\n",
    "            shortcat = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "        else:\n",
    "            shortcat = None\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel=inchannel, outchannel=outchannel, stride=stride, shortcat=shortcat))\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(ResidualBlock(inchannel=outchannel, outchannel=outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifies(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()\n",
    "input = t.randn(1,3,224,224)\n",
    "output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集处理 Kaggle: Dog vs Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from torchvision import transforms as T\n",
    "\n",
    "class DogCat(Dataset):\n",
    "    def __init__(self, root, transform = None):\n",
    "        dog_path = os.path.join(root, 'dog')\n",
    "        cat_path = os.path.join(root, 'cat')\n",
    "        dog_image = os.listdir(dog_path)\n",
    "        cat_image = os.listdir(cat_path)\n",
    "        self.imgs = [os.path.join(dog_path, i) for i in dog_image]\n",
    "        self.imgs.extend([os.path.join(cat_path, i) for i in cat_image])\n",
    "        self.transform = transform\n",
    "        self.class_map = {'dog': 1, 'cat': 2}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        file_path = Path(img)\n",
    "        parent_dir_name = file_path.parent.parent.name\n",
    "        classify = self.class_map.get(parent_dir_name, 0)\n",
    "        image = Image.open(img)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, classify\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]),\n",
    "])\n",
    "\n",
    "dataset = DogCat(root=\"./data/dogcat\", transform=transform)\n",
    "print(dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "dataset = ImageFolder(\"./data/dogcat/\", transform=transform)\n",
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅使用高级索引\n",
    "import torch as t\n",
    "a = t.arange(12).view(3,4)\n",
    "index1 = t.tensor([1,2])\n",
    "index2 = t.tensor([0,2])\n",
    "print(a[index1, index2])\n",
    "# 不同维度使使用广播原则\n",
    "index1 = t.tensor([1,2])[None, :]\n",
    "index2 = t.tensor([0,2])[:, None]\n",
    "print(a)\n",
    "print(index1)\n",
    "print(index2)\n",
    "a[index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高级索引和基本索引结合使用\n",
    "import torch as t\n",
    "a = t.arange(24).view(2,3,4)\n",
    "print(a)\n",
    "index1 = t.tensor([[1,0]]) # 维度为1*2\n",
    "index2 = t.tensor([[0,2]]) # 维度为1*2\n",
    "# 所有的高级索引相邻\n",
    "# 保留a的第一个维度，后面是索引的维度，也就是 2*1*2\n",
    "print(a[:, index1, index2])\n",
    "\n",
    "a = t.arange(120).view(2,3,4,5)\n",
    "# 将中间的两个维度替换为索引维度\n",
    "print(\"高级索引在中间位置：\",a[:, index1, index2, :].shape)\n",
    "\n",
    "# 高级索引不相邻，被基本索引分隔开\n",
    "print(\"高级索引被分隔开：\", a[index1, :, index2].shape)\n",
    "print(\"高级索引被分隔开：\", a[:, index1, :, index2].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动实现卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "# 使用双层循环实现数据提取\n",
    "def Conv_base(img, filters, stride, padding):\n",
    "    in_channel, Hin, Win = img.shape\n",
    "    _, out_channel, k, _ = filters.shape\n",
    "    Hout = ((Hin + 2*padding - k)/stride).long() + 1\n",
    "    Wout = ((Win + 2*padding - k)/stride).long() + 1\n",
    "\n",
    "    col = t.zeros(in_channel, k, k, Hout, Wout)\n",
    "    imgs = nn.ZeroPad2d(padding=padding.item())(img)\n",
    "\n",
    "    for i in range(Hout):\n",
    "        for j in range(Wout):\n",
    "            h = int(i*stride.item())\n",
    "            w = int(j*stride.item())\n",
    "            col[..., h, w] = imgs[:, h:h+k, w:w+k]\n",
    "    col = col.view(in_channel*k*k, Hout*Wout)\n",
    "    filters = filters.transpose(1,0).reshape(out_channel, in_channel*k*k)\n",
    "    return (filters @ col).view(out_channel, Hout, Wout)\n",
    "\n",
    "\n",
    "def Conv_index(img, filters, stride, padding):\n",
    "    in_channel, Hin, Win = img.shape\n",
    "    _, out_channel, k, _ = filters.shape\n",
    "    Hout = ((Hin + 2*padding - k)/stride).long() + 1\n",
    "    Wout = ((Win + 2*padding - k)/stride).long() + 1\n",
    "\n",
    "    k1 = t.arange(-(k//2), k//2+1)\n",
    "    index11, index12 = t.meshgrid(k1,k1)\n",
    "    stride = 1\n",
    "    Hout, Wout = 4, 4\n",
    "    H = t.linspace(k//2, k//2 + stride *(Hout-1), Hout).long()\n",
    "    W = t.linspace(k//2, k//2 + stride *(Wout-1), Wout).long()\n",
    "    index21, index22 = t.meshgrid(H, W)\n",
    "\n",
    "    index1 = index11[:, :, None, None] + index21[None, None, :, :]\n",
    "    index2 = index12[:, :, None, None] + index22[None, None, :, :]\n",
    "    filters = filters.transpose(1,0).reshape(out_channel, in_channel*k*k)\n",
    "    img = img[:, index1, index2].reshape(in_channel*k*k, Hout*Wout)\n",
    "    return (filters @ img).view(out_channel, Hout, Wout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单测试卷积代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = (t.ones(3,3,3,3) / 9).float()\n",
    "img = t.arange(36*3).view(3,6,6).float()\n",
    "stride, padding = t.tensor(1.), t.tensor(0)\n",
    "output = Conv_index(img, filters, stride, padding)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用cat图片测试卷积代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "dataset = DogCat(root=\"./data/dogcat\", transform=transform)\n",
    "img_data = dataset[0][0]\n",
    "img_data = (img_data * 255).to(t.uint8)\n",
    "# display(T.ToPILImage()(img_data))\n",
    "print(img_data.shape)\n",
    "filters = t.ones(3,3,32,32) / 9\n",
    "stride, padding = t.tensor(1.), t.tensor(0)\n",
    "output = Conv_base(img_data, filters, stride, padding)\n",
    "print(output.shape)\n",
    "display(T.ToPILImage()(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "k1 = t.arange(-(k//2), k//2+1)\n",
    "index11, index12 = t.meshgrid(k1,k1)\n",
    "stride = 1\n",
    "Hout, Wout = 4, 4\n",
    "H = t.linspace(k//2, k//2 + stride *(Hout-1), Hout).long()\n",
    "W = t.linspace(k//2, k//2 + stride *(Wout-1), Wout).long()\n",
    "index21, index22 = t.meshgrid(H, W)\n",
    "\n",
    "index1 = index11[:, :, None, None] + index21[None, None, :, :]\n",
    "index2 = index12[:, :, None, None] + index22[None, None, :, :]\n",
    "print(index11, index12)\n",
    "print(index21, index22)\n",
    "index1, index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0, 2, 2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "t.tensor([2,2,5,0]).reshape(1,4)[:,[2,3,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
