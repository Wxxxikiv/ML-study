{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据到data目录\n",
    "# import os\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# # 初始化 API\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()\n",
    "\n",
    "# # 下载竞赛数据集\n",
    "# api.competition_download_files(\"digit-recognizer\", path=\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa91d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "#隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['axes.unicode_minus'] = False      # 用来正常显示负号\n",
    "plt.rcParams['figure.dpi']         = 100        #分辨率\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # 1. 确保输入是2维图像（兜底）\n",
    "    transforms.Lambda(lambda x: x.reshape(28, 28) if x.ndim == 1 else x),\n",
    "    # 2. 转为float32（关键！将int转为float）\n",
    "    transforms.Lambda(lambda x: x.astype(np.float32) if isinstance(x, np.ndarray) else x.float()),\n",
    "    # 3. 转为张量（此时输入是float，输出也是float张量）\n",
    "    transforms.ToTensor(),\n",
    "    # 4. 标准化（保持原有参数）\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd43d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file, has_label=False, label_col='label', transform = None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param csv_file: CSV文件路径\n",
    "        :param has_label: 是否包含标签（训练数据为True，测试数据为False）\n",
    "        :param label_col: 标签列的列名（仅当has_label=True时有效）\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.has_label = has_label\n",
    "        self.transform = transform\n",
    "        # 提取特征（所有列，或排除标签列）\n",
    "        if has_label:\n",
    "            self.features = self.data.drop(columns=[label_col]).values\n",
    "            self.labels = self.data[label_col].values  # 仅当有标签时加载\n",
    "        else:\n",
    "            self.features = self.data.values  # 无标签时，所有列均为特征\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "        if self.has_label:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)  # 分类任务标签\n",
    "            return feature, label  # 有标签时返回（特征，标签）\n",
    "        else:\n",
    "            return feature  # 无标签时仅返回特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data = CSVDataset('data/train.csv',  has_label=True, label_col='label', transform=transform)\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data)-train_size\n",
    "train_dataset, test_dataset= random_split(\n",
    "    data, \n",
    "    [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# for i in range(12):\n",
    "#     plt.subplot(3, 4, i+1)\n",
    "#     plt.tight_layout()\n",
    "#     image, label = train_dataset[i]\n",
    "#     plt.imshow(image.reshape(28, 28), cmap='gray', interpolation='none')\n",
    "#     plt.title(\"Labels: {}\".format(label))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64*5*5, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "# 查看模型结构\n",
    "# 打印模型参数总数和可训练参数总数\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())  # 所有参数数量\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)  # 需要训练的参数数量\n",
    "    print(f\"模型总参数数量: {total_params:,}\")\n",
    "    print(f\"模型可训练参数数量: {trainable_params:,}\")\n",
    "\n",
    "print(model)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn    = torch.nn.CrossEntropyLoss() # 交叉熵损失函数，常用在多分类任务中\n",
    "learn_rate = 0.01 # 学习率\n",
    "optimizer  = torch.optim.SGD(model.parameters(), lr=learn_rate, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eeb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc  += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    train_acc  /= size\n",
    "    train_loss /= num_batches\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_acc = 0, 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "\n",
    "        test_acc  += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss += loss.item()\n",
    "    test_acc  /= size\n",
    "    test_loss /= num_batches\n",
    "    return test_acc, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb78a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader, model):\n",
    "    \"\"\"\n",
    "    对测试集进行预测，返回所有样本的预测标签\n",
    "    \n",
    "    参数：\n",
    "        dataloader: 测试集的DataLoader（无标签数据）\n",
    "        model: 训练好的模型\n",
    "        device: 运行设备（如'cuda'或'cpu'）\n",
    "    \n",
    "    返回：\n",
    "        predictions: 所有样本的预测标签列表（numpy数组）\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换模型到评估模式（关闭dropout、批归一化固定等）\n",
    "    predictions = []  # 存储所有预测结果\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算，节省内存和计算资源\n",
    "        for x in dataloader:  # 测试集无标签，每次迭代仅获取特征x\n",
    "            x = x.to(device)  # 转移数据到指定设备\n",
    "            y_pred = model(x)  # 模型输出预测概率（形状：[batch_size, num_classes]）\n",
    "            pred_label = y_pred.argmax(1)  # 取概率最大的类别作为预测标签（形状：[batch_size]）\n",
    "            predictions.extend(pred_label.cpu().numpy())  # 转移到CPU并转为numpy，存入列表\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99caba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 10\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_train_acc, epoch_train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "    train_acc.append(epoch_train_acc)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_test_acc, epoch_test_loss = test(test_loader, model, loss_fn)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "\n",
    "    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}')\n",
    "    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9209fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(epochs_range, train_acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, test_acc, label='Test Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, test_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = CSVDataset('data/test.csv',  has_label=False, transform=transform)\n",
    "pred_loader = DataLoader(pred_dataset, batch_size=batch_size, shuffle=False)\n",
    "result = predict(pred_loader, model)\n",
    "image_ids = np.arange(1, len(result) + 1)\n",
    "submission_df = pd.DataFrame({\n",
    "        'ImageId': image_ids,\n",
    "        'Label': result\n",
    "    })\n",
    "submission_df.to_csv('data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
